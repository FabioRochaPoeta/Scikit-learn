{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Scikit-learn</h1>\n",
    "\n",
    "From Oficial site: https://scikit-learn.org\n",
    "\n",
    "\"In order to avoid potential conflicts with other packages it is strongly recommended to use a virtual environment (venv) or a conda environment.\" \n",
    "\n",
    "Here we use a venv ( https://github.com/FabioRochaPoeta/initializaing-git-automated-power-shell ) in 3 basic examples. User guide: https://scikit-learn.org/stable/user_guide.html\n",
    "\n",
    "And here is 15 most important features of this library: https://www.analyticsvidhya.com/blog/2021/07/15-most-important-features-of-scikit-learn/"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "O QUE É\n",
    "\n",
    "Uma biblioteca da linguagem Python open source de análise de dados, a mais útil e robusta para Machine Learning. Resumo do USER GUIDE:\n",
    "- Supervised / Unsupervised learning\n",
    "- Model selection and evaluation\n",
    "- Inspection\n",
    "- Visualizations\n",
    "- Dataset transformations / Loading utilities\n",
    "\n",
    "USOS\n",
    "\n",
    "Desenvolvimento de modelos de classificação e regressão para previsão de resultados em problemas de negócios e científicos;\n",
    "Análise de dados e extração de insights por meio de técnicas de clusterização e decomposição de dados;\n",
    "Pré-processamento de dados, incluindo tratamento de dados faltantes, normalização, codificação de variáveis categóricas e seleção de características relevantes para o modelo;\n",
    "Seleção e ajuste de modelos de aprendizado de máquina, incluindo a escolha de hiperparâmetros e avaliação de desempenho por meio de validação cruzada\n",
    "\n",
    "VANTAGENS\n",
    "\n",
    "Ser uma biblioteca de código aberto, com uma grande comunidade de desenvolvedores e usuários ativos que contribuem com novos recursos e correções de bugs;\n",
    "Possuir uma interface consistente e intuitiva que facilita o desenvolvimento de modelos de aprendizado de máquina;\n",
    "Ter uma documentação abrangente e de alta qualidade, com muitos exemplos e tutoriais que ajudam a entender os conceitos e as funcionalidades da biblioteca;\n",
    "Ser compatível com outras bibliotecas populares do ecossistema de ciência de dados do Python, como NumPy, Pandas e Matplotlib."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting scikit-learn\n",
      "  Using cached scikit_learn-1.2.2-cp310-cp310-win_amd64.whl (8.3 MB)\n",
      "Collecting threadpoolctl>=2.0.0\n",
      "  Using cached threadpoolctl-3.1.0-py3-none-any.whl (14 kB)\n",
      "Requirement already satisfied: numpy>=1.17.3 in c:\\users\\fabio\\documents\\github\\repos\\scikit-learn\\.venv\\lib\\site-packages (from scikit-learn) (1.24.2)\n",
      "Collecting scipy>=1.3.2\n",
      "  Using cached scipy-1.10.1-cp310-cp310-win_amd64.whl (42.5 MB)\n",
      "Collecting joblib>=1.1.1\n",
      "  Using cached joblib-1.2.0-py3-none-any.whl (297 kB)\n",
      "Installing collected packages: threadpoolctl, scipy, joblib, scikit-learn\n",
      "Successfully installed joblib-1.2.0 scikit-learn-1.2.2 scipy-1.10.1 threadpoolctl-3.1.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 23.0.1 -> 23.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "# Installing\n",
    "%pip install -U scikit-learn"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cross-griding e Pipeline\n",
    "\n",
    "Cross-Griding e Pipeline são duas funcionalidades importantes da biblioteca Scikit-Learn para desenvolvimento de modelos de aprendizado de máquina.\n",
    "\n",
    "Cross-Griding, ou busca em grade com validação cruzada, é uma técnica que permite testar diferentes combinações de hiperparâmetros para um modelo de aprendizado de máquina, a fim de encontrar a combinação que oferece o melhor desempenho em dados novos e desconhecidos.\n",
    "\n",
    "O objetivo é explorar o espaço de parâmetros do modelo, testando todas as combinações possíveis, a fim de encontrar os melhores parâmetros que otimizam o desempenho do modelo. A validação cruzada é utilizada para avaliar o desempenho do modelo para cada combinação de parâmetros testados.\n",
    "\n",
    "Já o Pipeline é uma técnica que permite encadear vários passos de pré-processamento de dados e modelagem em um único objeto. Isso facilita o desenvolvimento de modelos de aprendizado de máquina, pois evita a repetição de código para cada etapa do processo.\n",
    "\n",
    "Com o Pipeline, é possível definir uma sequência de transformações para pré-processar os dados (por exemplo, normalização, seleção de características, codificação de variáveis categóricas) e um modelo de aprendizado de máquina para treinar e testar os dados. Em seguida, podemos executar a busca em grade (Grid Search) nos hiperparâmetros do modelo com validação cruzada, como explicado anteriormente.\n",
    "\n",
    "Usar Cross-Griding com validação cruzada e Pipeline em conjunto pode trazer muitos benefícios, uma vez que podemos testar diferentes combinações de pré-processamento de dados e parâmetros do modelo, garantindo que o modelo final tenha o melhor desempenho possível. Além disso, essa técnica permite economizar tempo e evitar erros, já que todo o processo é automatizado e sequencial.\n",
    "\n",
    "Neste exemplo, estamos usando o conjunto de dados Iris para treinar um modelo SVM. Primeiro, carregamos os dados e os dividimos em conjuntos de treinamento e teste. Em seguida, definimos um pipeline que normaliza os dados e treina um modelo SVM. Também definimos um grid de parâmetros a serem testados pelo Grid Search, que consiste em diferentes valores para os parâmetros C e kernel do SVM.\n",
    "\n",
    "Ao executar o Grid Search com validação cruzada, o Scikit-Learn testa todas as combinações de valores de parâmetros do grid e retorna o melhor conjunto de parâmetros encontrados. Finalmente, avaliamos o desempenho do modelo com os dados de teste e imprimimos o score final e os melhores parâmetros encontrados pelo Grid Search.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score final: 0.97\n",
      "Melhores parâmetros: {'svm__C': 1, 'svm__kernel': 'linear'}\n"
     ]
    }
   ],
   "source": [
    "# Importação das bibliotecas necessárias\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "# Carregamento dos dados\n",
    "iris = load_iris()\n",
    "X_train, X_test, y_train, y_test = train_test_split(iris.data, iris.target, random_state=0)\n",
    "\n",
    "# Definição do pipeline\n",
    "pipeline = Pipeline([\n",
    "    ('scaler', StandardScaler()),  # normalização dos dados\n",
    "    ('svm', SVC())  # modelo SVM\n",
    "])\n",
    "\n",
    "# Definição do grid de parâmetros a serem testados\n",
    "param_grid = {\n",
    "    'svm__C': [0.1, 1, 10],  # parâmetro C do SVM\n",
    "    'svm__kernel': ['linear', 'rbf'],  # parâmetro kernel do SVM\n",
    "}\n",
    "\n",
    "# Configuração do Grid Search com validação cruzada\n",
    "grid_search = GridSearchCV(pipeline, param_grid=param_grid, cv=5)\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Avaliação do desempenho do modelo\n",
    "score = grid_search.score(X_test, y_test)\n",
    "print(f\"Score final: {score:.2f}\")\n",
    "\n",
    "# Imprime os melhores parâmetros encontrados\n",
    "print(f\"Melhores parâmetros: {grid_search.best_params_}\")\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>1. Preprocessing (Dataset Transformations)</h2> - https://scikit-learn.org/stable/modules/preprocessing.html\n",
    "\n",
    "O escalonamento de dados é uma etapa de pré-processamento de dados para recursos numéricos. Muitos algoritmos de aprendizado de máquina, como métodos de descida gradiente, algoritmo KNN, regressão linear e logística, etc., requerem escalonamento de dados para produzir bons resultados.\n",
    "\n",
    "O Standard Scaler ajuda a obter uma distribuição padronizada, com média zero e desvio padrão de um (variância da unidade). Ele padroniza os recursos subtraindo o valor médio do recurso e, em seguida, dividindo o resultado pelo desvio padrão do recurso. \n",
    "\n",
    "A escala padrão é calculada como: \n",
    "\n",
    "z = (x - u) / s\n",
    "\n",
    "Onde,\n",
    "\n",
    "z são dados em escala.\n",
    "x deve ser um dado escalado.\n",
    "u é a média das amostras de treinamento\n",
    "s é o desvio padrão das amostras de treinamento.\n",
    "\n",
    "Sintaxe: class sklearn.preprocessing.StandardScaler (*, copy = True, with_mean = True, with_std = True)\n",
    "\n",
    "Parâmetros:\n",
    "copy: Se False, o dimensionamento local é feito. Se True, a cópia é criada em vez do dimensionamento local.\n",
    "with_mean: se True, os dados são centralizados antes do escalonamento.\n",
    "with_std: se True, os dados são escalados para a variação da unidade."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original data:\n",
      " [[1, -1, 2], [2, 0, 0], [0, 1, -1]] \n",
      "\n",
      "\n",
      "Scaled data:\n",
      " [[ 0.         -1.22474487  1.33630621]\n",
      " [ 1.22474487  0.         -0.26726124]\n",
      " [-1.22474487  1.22474487 -1.06904497]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Load dataset - create an instance of the StandardScaler class and fit it to the data using the fit method\n",
    "X = [[1, -1, 2], \n",
    "     [2, 0, 0], \n",
    "     [0, 1, -1]]\n",
    "scaler = StandardScaler().fit(X)\n",
    "\n",
    "# Transform the data using the transform method and store the scaled data in the X_scaled variable\n",
    "X_scaled = scaler.transform(X)\n",
    "\n",
    "# Print results - print both the original and scaled data to the console\n",
    "print(\"Original data:\\n\", X, \"\\n\\n\")\n",
    "print(\"Scaled data:\\n\", X_scaled)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>2. Cross-Validating (Model selection and evaluation)</h2> - https://scikit-learn.org/stable/modules/cross_validation.html\n",
    "\n",
    "Cross Validation é uma técnica muito utilizada para avaliação de desempenho (validação) de modelos de aprendizado de máquina. O CV consiste em particionar os dados em conjuntos(partes), onde um conjunto é utilizado para treino e outro conjunto é utilizado para teste e avaliação do desempenho do modelo.\n",
    "\n",
    "A validação cruzada é um método de reamostragem e tem como objetivo avaliar a capacidade de generalização do seu modelo. Em outras palavras, verificar o quão pronto seu modelo está para receber novos dados. Quando nós estamos avaliando nosso modelo, seja usando a função .score() do Scikit-learn ou qualquer outra, nosso principal objetivo é saber quão bem nosso modelo irá generalizar, ou seja, ela serve para sabermos se o nosso modelo será efetivo ao receber um dado que ele nunca viu na vida.\n",
    "\n",
    "Ao executarmos essa função, nós teremos que passar dois principais parâmetros nela: as features de treino ou teste (X), e a label — ou rótulo — esperada (Y).\n",
    "\n",
    "A função cross_val_score tem como resultado de saída uma lista com os scores de cada iteração feita com cada parte(fold) do método cross validation. \n",
    "\n",
    "Como resultado dessa função, você deverá receber um número que vai de 0.0 a 1.0, onde quanto mais próximo de 1.0, melhor. Mas, não se esqueça que é muito importante que seu modelo não tenha um score absurdamente alto no conjunto de treino, enquanto no de teste ele está bem baixo. Quando isso acontece, você está enfrentando um problema de Overfitting — quando o modelo “adivinha” muito bem os dados que foram usados para treiná-lo, mas ele não consegue se sair muito bem com dados que nunca viu. Há também os casos de Underfitting, onde seu modelo não consegue entender a tendência dos dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross-validation scores: [0.96666667 0.96666667 0.9        0.96666667 1.        ]\n",
      "Mean score: 0.9600000000000002\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "# Load dataset - load the Iris dataset using the load_iris function\n",
    "iris = load_iris()\n",
    "\n",
    "# Train model with cross-validation - create an instance of the DecisionTreeClassifier class \n",
    "# and use the cross_val_score function to train and evaluate the model using 5-fold cross-validation\n",
    "model = DecisionTreeClassifier()\n",
    "scores = cross_val_score(model, iris.data, iris.target, cv=5)\n",
    "\n",
    "# Print results - print the cross-validation scores and their mean to the console\n",
    "print(\"Cross-validation scores:\", scores)\n",
    "print(\"Mean score:\", scores.mean())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'data': array([[5.1, 3.5, 1.4, 0.2],\n",
       "        [4.9, 3. , 1.4, 0.2],\n",
       "        [4.7, 3.2, 1.3, 0.2],\n",
       "        [4.6, 3.1, 1.5, 0.2],\n",
       "        [5. , 3.6, 1.4, 0.2],\n",
       "        [5.4, 3.9, 1.7, 0.4],\n",
       "        [4.6, 3.4, 1.4, 0.3],\n",
       "        [5. , 3.4, 1.5, 0.2],\n",
       "        [4.4, 2.9, 1.4, 0.2],\n",
       "        [4.9, 3.1, 1.5, 0.1],\n",
       "        [5.4, 3.7, 1.5, 0.2],\n",
       "        [4.8, 3.4, 1.6, 0.2],\n",
       "        [4.8, 3. , 1.4, 0.1],\n",
       "        [4.3, 3. , 1.1, 0.1],\n",
       "        [5.8, 4. , 1.2, 0.2],\n",
       "        [5.7, 4.4, 1.5, 0.4],\n",
       "        [5.4, 3.9, 1.3, 0.4],\n",
       "        [5.1, 3.5, 1.4, 0.3],\n",
       "        [5.7, 3.8, 1.7, 0.3],\n",
       "        [5.1, 3.8, 1.5, 0.3],\n",
       "        [5.4, 3.4, 1.7, 0.2],\n",
       "        [5.1, 3.7, 1.5, 0.4],\n",
       "        [4.6, 3.6, 1. , 0.2],\n",
       "        [5.1, 3.3, 1.7, 0.5],\n",
       "        [4.8, 3.4, 1.9, 0.2],\n",
       "        [5. , 3. , 1.6, 0.2],\n",
       "        [5. , 3.4, 1.6, 0.4],\n",
       "        [5.2, 3.5, 1.5, 0.2],\n",
       "        [5.2, 3.4, 1.4, 0.2],\n",
       "        [4.7, 3.2, 1.6, 0.2],\n",
       "        [4.8, 3.1, 1.6, 0.2],\n",
       "        [5.4, 3.4, 1.5, 0.4],\n",
       "        [5.2, 4.1, 1.5, 0.1],\n",
       "        [5.5, 4.2, 1.4, 0.2],\n",
       "        [4.9, 3.1, 1.5, 0.2],\n",
       "        [5. , 3.2, 1.2, 0.2],\n",
       "        [5.5, 3.5, 1.3, 0.2],\n",
       "        [4.9, 3.6, 1.4, 0.1],\n",
       "        [4.4, 3. , 1.3, 0.2],\n",
       "        [5.1, 3.4, 1.5, 0.2],\n",
       "        [5. , 3.5, 1.3, 0.3],\n",
       "        [4.5, 2.3, 1.3, 0.3],\n",
       "        [4.4, 3.2, 1.3, 0.2],\n",
       "        [5. , 3.5, 1.6, 0.6],\n",
       "        [5.1, 3.8, 1.9, 0.4],\n",
       "        [4.8, 3. , 1.4, 0.3],\n",
       "        [5.1, 3.8, 1.6, 0.2],\n",
       "        [4.6, 3.2, 1.4, 0.2],\n",
       "        [5.3, 3.7, 1.5, 0.2],\n",
       "        [5. , 3.3, 1.4, 0.2],\n",
       "        [7. , 3.2, 4.7, 1.4],\n",
       "        [6.4, 3.2, 4.5, 1.5],\n",
       "        [6.9, 3.1, 4.9, 1.5],\n",
       "        [5.5, 2.3, 4. , 1.3],\n",
       "        [6.5, 2.8, 4.6, 1.5],\n",
       "        [5.7, 2.8, 4.5, 1.3],\n",
       "        [6.3, 3.3, 4.7, 1.6],\n",
       "        [4.9, 2.4, 3.3, 1. ],\n",
       "        [6.6, 2.9, 4.6, 1.3],\n",
       "        [5.2, 2.7, 3.9, 1.4],\n",
       "        [5. , 2. , 3.5, 1. ],\n",
       "        [5.9, 3. , 4.2, 1.5],\n",
       "        [6. , 2.2, 4. , 1. ],\n",
       "        [6.1, 2.9, 4.7, 1.4],\n",
       "        [5.6, 2.9, 3.6, 1.3],\n",
       "        [6.7, 3.1, 4.4, 1.4],\n",
       "        [5.6, 3. , 4.5, 1.5],\n",
       "        [5.8, 2.7, 4.1, 1. ],\n",
       "        [6.2, 2.2, 4.5, 1.5],\n",
       "        [5.6, 2.5, 3.9, 1.1],\n",
       "        [5.9, 3.2, 4.8, 1.8],\n",
       "        [6.1, 2.8, 4. , 1.3],\n",
       "        [6.3, 2.5, 4.9, 1.5],\n",
       "        [6.1, 2.8, 4.7, 1.2],\n",
       "        [6.4, 2.9, 4.3, 1.3],\n",
       "        [6.6, 3. , 4.4, 1.4],\n",
       "        [6.8, 2.8, 4.8, 1.4],\n",
       "        [6.7, 3. , 5. , 1.7],\n",
       "        [6. , 2.9, 4.5, 1.5],\n",
       "        [5.7, 2.6, 3.5, 1. ],\n",
       "        [5.5, 2.4, 3.8, 1.1],\n",
       "        [5.5, 2.4, 3.7, 1. ],\n",
       "        [5.8, 2.7, 3.9, 1.2],\n",
       "        [6. , 2.7, 5.1, 1.6],\n",
       "        [5.4, 3. , 4.5, 1.5],\n",
       "        [6. , 3.4, 4.5, 1.6],\n",
       "        [6.7, 3.1, 4.7, 1.5],\n",
       "        [6.3, 2.3, 4.4, 1.3],\n",
       "        [5.6, 3. , 4.1, 1.3],\n",
       "        [5.5, 2.5, 4. , 1.3],\n",
       "        [5.5, 2.6, 4.4, 1.2],\n",
       "        [6.1, 3. , 4.6, 1.4],\n",
       "        [5.8, 2.6, 4. , 1.2],\n",
       "        [5. , 2.3, 3.3, 1. ],\n",
       "        [5.6, 2.7, 4.2, 1.3],\n",
       "        [5.7, 3. , 4.2, 1.2],\n",
       "        [5.7, 2.9, 4.2, 1.3],\n",
       "        [6.2, 2.9, 4.3, 1.3],\n",
       "        [5.1, 2.5, 3. , 1.1],\n",
       "        [5.7, 2.8, 4.1, 1.3],\n",
       "        [6.3, 3.3, 6. , 2.5],\n",
       "        [5.8, 2.7, 5.1, 1.9],\n",
       "        [7.1, 3. , 5.9, 2.1],\n",
       "        [6.3, 2.9, 5.6, 1.8],\n",
       "        [6.5, 3. , 5.8, 2.2],\n",
       "        [7.6, 3. , 6.6, 2.1],\n",
       "        [4.9, 2.5, 4.5, 1.7],\n",
       "        [7.3, 2.9, 6.3, 1.8],\n",
       "        [6.7, 2.5, 5.8, 1.8],\n",
       "        [7.2, 3.6, 6.1, 2.5],\n",
       "        [6.5, 3.2, 5.1, 2. ],\n",
       "        [6.4, 2.7, 5.3, 1.9],\n",
       "        [6.8, 3. , 5.5, 2.1],\n",
       "        [5.7, 2.5, 5. , 2. ],\n",
       "        [5.8, 2.8, 5.1, 2.4],\n",
       "        [6.4, 3.2, 5.3, 2.3],\n",
       "        [6.5, 3. , 5.5, 1.8],\n",
       "        [7.7, 3.8, 6.7, 2.2],\n",
       "        [7.7, 2.6, 6.9, 2.3],\n",
       "        [6. , 2.2, 5. , 1.5],\n",
       "        [6.9, 3.2, 5.7, 2.3],\n",
       "        [5.6, 2.8, 4.9, 2. ],\n",
       "        [7.7, 2.8, 6.7, 2. ],\n",
       "        [6.3, 2.7, 4.9, 1.8],\n",
       "        [6.7, 3.3, 5.7, 2.1],\n",
       "        [7.2, 3.2, 6. , 1.8],\n",
       "        [6.2, 2.8, 4.8, 1.8],\n",
       "        [6.1, 3. , 4.9, 1.8],\n",
       "        [6.4, 2.8, 5.6, 2.1],\n",
       "        [7.2, 3. , 5.8, 1.6],\n",
       "        [7.4, 2.8, 6.1, 1.9],\n",
       "        [7.9, 3.8, 6.4, 2. ],\n",
       "        [6.4, 2.8, 5.6, 2.2],\n",
       "        [6.3, 2.8, 5.1, 1.5],\n",
       "        [6.1, 2.6, 5.6, 1.4],\n",
       "        [7.7, 3. , 6.1, 2.3],\n",
       "        [6.3, 3.4, 5.6, 2.4],\n",
       "        [6.4, 3.1, 5.5, 1.8],\n",
       "        [6. , 3. , 4.8, 1.8],\n",
       "        [6.9, 3.1, 5.4, 2.1],\n",
       "        [6.7, 3.1, 5.6, 2.4],\n",
       "        [6.9, 3.1, 5.1, 2.3],\n",
       "        [5.8, 2.7, 5.1, 1.9],\n",
       "        [6.8, 3.2, 5.9, 2.3],\n",
       "        [6.7, 3.3, 5.7, 2.5],\n",
       "        [6.7, 3. , 5.2, 2.3],\n",
       "        [6.3, 2.5, 5. , 1.9],\n",
       "        [6.5, 3. , 5.2, 2. ],\n",
       "        [6.2, 3.4, 5.4, 2.3],\n",
       "        [5.9, 3. , 5.1, 1.8]]),\n",
       " 'target': array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2]),\n",
       " 'frame': None,\n",
       " 'target_names': array(['setosa', 'versicolor', 'virginica'], dtype='<U10'),\n",
       " 'DESCR': '.. _iris_dataset:\\n\\nIris plants dataset\\n--------------------\\n\\n**Data Set Characteristics:**\\n\\n    :Number of Instances: 150 (50 in each of three classes)\\n    :Number of Attributes: 4 numeric, predictive attributes and the class\\n    :Attribute Information:\\n        - sepal length in cm\\n        - sepal width in cm\\n        - petal length in cm\\n        - petal width in cm\\n        - class:\\n                - Iris-Setosa\\n                - Iris-Versicolour\\n                - Iris-Virginica\\n                \\n    :Summary Statistics:\\n\\n    ============== ==== ==== ======= ===== ====================\\n                    Min  Max   Mean    SD   Class Correlation\\n    ============== ==== ==== ======= ===== ====================\\n    sepal length:   4.3  7.9   5.84   0.83    0.7826\\n    sepal width:    2.0  4.4   3.05   0.43   -0.4194\\n    petal length:   1.0  6.9   3.76   1.76    0.9490  (high!)\\n    petal width:    0.1  2.5   1.20   0.76    0.9565  (high!)\\n    ============== ==== ==== ======= ===== ====================\\n\\n    :Missing Attribute Values: None\\n    :Class Distribution: 33.3% for each of 3 classes.\\n    :Creator: R.A. Fisher\\n    :Donor: Michael Marshall (MARSHALL%PLU@io.arc.nasa.gov)\\n    :Date: July, 1988\\n\\nThe famous Iris database, first used by Sir R.A. Fisher. The dataset is taken\\nfrom Fisher\\'s paper. Note that it\\'s the same as in R, but not as in the UCI\\nMachine Learning Repository, which has two wrong data points.\\n\\nThis is perhaps the best known database to be found in the\\npattern recognition literature.  Fisher\\'s paper is a classic in the field and\\nis referenced frequently to this day.  (See Duda & Hart, for example.)  The\\ndata set contains 3 classes of 50 instances each, where each class refers to a\\ntype of iris plant.  One class is linearly separable from the other 2; the\\nlatter are NOT linearly separable from each other.\\n\\n.. topic:: References\\n\\n   - Fisher, R.A. \"The use of multiple measurements in taxonomic problems\"\\n     Annual Eugenics, 7, Part II, 179-188 (1936); also in \"Contributions to\\n     Mathematical Statistics\" (John Wiley, NY, 1950).\\n   - Duda, R.O., & Hart, P.E. (1973) Pattern Classification and Scene Analysis.\\n     (Q327.D83) John Wiley & Sons.  ISBN 0-471-22361-1.  See page 218.\\n   - Dasarathy, B.V. (1980) \"Nosing Around the Neighborhood: A New System\\n     Structure and Classification Rule for Recognition in Partially Exposed\\n     Environments\".  IEEE Transactions on Pattern Analysis and Machine\\n     Intelligence, Vol. PAMI-2, No. 1, 67-71.\\n   - Gates, G.W. (1972) \"The Reduced Nearest Neighbor Rule\".  IEEE Transactions\\n     on Information Theory, May 1972, 431-433.\\n   - See also: 1988 MLC Proceedings, 54-64.  Cheeseman et al\"s AUTOCLASS II\\n     conceptual clustering system finds 3 classes in the data.\\n   - Many, many more ...',\n",
       " 'feature_names': ['sepal length (cm)',\n",
       "  'sepal width (cm)',\n",
       "  'petal length (cm)',\n",
       "  'petal width (cm)'],\n",
       " 'filename': 'iris.csv',\n",
       " 'data_module': 'sklearn.datasets.data'}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "iris"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>3. Clustering Data (Unsupervised learning)</h2> - https://scikit-learn.org/stable/modules/clustering.html#overview-of-clustering-methods\n",
    "\n",
    "A clusterização de dados é uma técnica que visa fazer agrupamentos automáticos de dados, levando em consideração o grau de semelhança, tem por objetivo agrupar através de aprendizado não supervisionado casos de uma base em k grupos, também denominados clusters.\n",
    "\n",
    "K-Means é um algoritmo de clusterização (ou agrupamento) disponível na biblioteca Scikit-Learn.\n",
    "\n",
    "É um algoritmo de aprendizado não supervisionado (ou seja, que não precisa de inputs de confirmação externos) que avalia e clusteriza os dados de acordo com suas características, como por exemplo:\n",
    "\n",
    "lojas/centro logístico\n",
    "clientes/produtos ou serviços semelhantes\n",
    "clientes/características semelhantes\n",
    "séries/gênero da série ou faixa etária\n",
    "usuarios de uma rede social/usuario influenciador\n",
    "paciente/sintoma ou característica semelhante\n",
    "\n",
    "Por exemplo, se eu tenho uma rede de lojas com abrangência nacional, qual seria os melhores lugares para construir os centros logísticos de abastecimento?\n",
    "\n",
    "Podemos começar a responder isso com K-means.\n",
    "\n",
    "Como funciona?\n",
    "Primeiro, preciso definir um ‘K’, ou seja, um número de clusters (ou agrupamentos).\n",
    "Depois, preciso definir, aleatoriamente, um centroide para cada cluster.\n",
    "O próximo passo é calcular, para cada ponto, o centroide de menor distância. Cada ponto pertencerá ao centroide mais próximo (lembrar do exemplo do CD logístico e das lojas: cada loja (ponto) deve ser atendida pelo CD (centróide) mais próximo)\n",
    "Agora, devo reposicionar o centróide. A nova posição do centroide deve ser a média da posição de todos os pontos do cluster.\n",
    "Os dois ultimos passos são repetidos, iterativamente, até obtermos a posição ideal dos centróides."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cluster labels: [0 0 1 2 2 0 1 1 1 1 2 0 2 1 1 1 2 2 2 2 1 0 0 0 1 2 2 2 1 1 0 0 1 2 2 0 0\n",
      " 1 0 0 2 1 2 0 2 0 2 2 0 1 0 2 1 0 2 0 2 2 2 1 1 2 0 0 2 2 0 1 1 2 0 2 1 1\n",
      " 1 0 1 2 2 2 1 2 2 2 1 0 1 0 2 2 2 2 1 1 0 1 0 2 1 1 1 0 0 2 0 1 1 2 1 2 0\n",
      " 1 1 1 2 1 0 0 1 2 2 1 0 1 0 0 1 0 1 1 2 1 1 0 2 0 2 1 1 1 2 2 0 0 0 2 1 2\n",
      " 2 2 2 0 1 0 2 1 2 1 2 0 1 2 2 1 2 2 1 1 0 0 1 2 2 1 2 0 1 0 1 0 2 1 2 1 2\n",
      " 0 2 0 2 0 1 2 1 1 2 0 1 1 1 0 2 1 2 2 1 2 1 2 2 1 1 0 0 1 1 2 0 2 0 1 0 0\n",
      " 1 2 0 2 2 1 0 2 2 0 2 0 1 1 0 1 0 1 0 0 0 1 0 2 1 2 1 2 1 1 0 1 2 1 2 1 1\n",
      " 1 1 2 0 1 0 0 1 2 2 0 1 2 1 1 2 0 2 0 0 1 0 1 0 1 1 2 2 1 2 0 0 2 1 1 0 2\n",
      " 1 0 0 2 0 0 1 0 2 1 0 1 0 0 0 0 0 1 0 0 1 2 0 0 1 0 0 1 0 1 2 1 2 2 1 1 0\n",
      " 0 0 2 0 1 0 1 0 1 1 1 2 2 0 0 2 2 2 2 2 1 2 2 1 2 2 0 1 1 1 1 0 1 0 0 0 1\n",
      " 1 2 2 1 2 1 2 0 1 2 0 1 0 1 1 0 2 0 1 0 1 2 0 2 0 0 0 2 1 2 2 0 2 1 2 0 1\n",
      " 2 2 0 1 2 0 0 0 1 0 2 0 1 2 2 2 2 2 0 1 0 1 1 2 2 0 2 0 1 0 1 0 2 0 0 0 1\n",
      " 2 2 1 2 0 0 0 0 2 2 0 2 1 0 1 2 1 1 2 2 1 1 1 0 1 2 0 2 2 0 0 1 0 2 1 2 0\n",
      " 1 0 1 1 2 1 0 2 2 2 1 2 0 2 0 1 1 0 0 0 2 0 2 2 1 2 1 2 1 2 0 1 2 0 1 0 2\n",
      " 2 2 2 2 2 1 0 2 1 1 1 2 2 1 2 0 1 2 2 1 1 0 0 0 0 2 0 2 2 2 0 0 0 2 2 2 2\n",
      " 2 0 1 2 2 2 2 2 2 0 0 1 1 2 2 1 1 0 0 2 0 0 0 1 2 0 0 0 2 0 2 0 1 1 0 0 0\n",
      " 0 2 1 1 2 1 2 1 1 1 1 2 0 0 1 2 0 2 2 0 2 0 0 1 0 2 2 0 1 1 2 2 0 0 1 0 1\n",
      " 2 1 0 0 2 2 0 2 1 0 1 0 1 2 1 0 2 2 1 0 0 1 1 0 0 1 0 2 2 1 2 1 0 2 0 1 1\n",
      " 2 2 0 2 1 1 0 2 0 0 0 1 0 2 1 0 1 2 1 2 1 1 2 2 0 1 2 1 2 1 1 0 2 0 2 0 1\n",
      " 1 1 0 1 0 1 1 0 0 2 2 0 0 2 1 0 1 2 1 1 0 2 2 0 1 0 2 2 0 1 2 1 2 1 0 1 1\n",
      " 0 0 0 1 1 2 2 1 1 0 1 2 0 0 0 0 0 0 0 0 0 0 1 2 1 0 2 2 2 0 1 0 1 2 1 0 2\n",
      " 2 1 0 1 0 2 1 0 2 0 0 1 1 0 2 0 1 2 2 2 0 1 0 0 2 0 1 2 1 1 0 2 2 2 2 2 0\n",
      " 2 0 0 0 0 2 1 0 0 1 2 2 1 1 0 2 1 0 2 0 1 2 2 0 1 1 2 1 1 1 2 1 0 0 2 1 0\n",
      " 0 0 1 0 1 0 0 1 1 2 0 2 0 0 2 0 0 0 2 0 0 1 1 0 1 1 2 2 2 2 0 0 1 1 1 0 2\n",
      " 1 1 1 1 1 0 2 0 0 2 1 0 0 2 1 2 2 0 2 0 2 0 2 1 1 1 0 0 2 1 1 0 0 0 1 2 1\n",
      " 0 1 2 2 2 0 2 2 0 1 0 0 1 2 2 0 2 1 1 1 1 1 2 2 1 1 2 2 1 2 0 2 2 0 2 1 1\n",
      " 0 1 0 2 0 2 0 1 2 0 1 2 1 0 1 0 2 0 1 2 2 1 0 2 2 2 1 1 2 2 1 1 1 0 2 1 1\n",
      " 0]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Fabio\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\cluster\\_kmeans.py:870: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import make_blobs\n",
    "from sklearn.cluster import KMeans\n",
    "\n",
    "# Generate synthetic data - with 3 clusters (centers)\n",
    "X, y = make_blobs(n_samples=1000, centers=3, random_state=42)\n",
    "\n",
    "# Cluster data - instance of the KMeans class with three clusters and fit it to the data using the fit_predict method\n",
    "kmeans = KMeans(n_clusters=3, random_state=42)\n",
    "labels = kmeans.fit_predict(X)\n",
    "\n",
    "# Print results - print the cluster labels assigned by the algorithm to the console\n",
    "print(\"Cluster labels:\", labels)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[-6.59633932, -7.13901457],\n",
       "        [-6.13753182, -6.58081701],\n",
       "        [ 5.19820575,  2.04917508],\n",
       "        ...,\n",
       "        [ 3.69047995,  4.60555175],\n",
       "        [ 4.03036663,  1.78619838],\n",
       "        [-7.44179522, -7.08933147]]),\n",
       " array([2, 2, 1, 0, 0, 2, 1, 1, 1, 1, 0, 2, 0, 1, 1, 1, 0, 0, 0, 0, 1, 2,\n",
       "        2, 2, 1, 0, 0, 0, 1, 1, 2, 2, 1, 0, 0, 2, 2, 1, 2, 2, 0, 1, 0, 2,\n",
       "        0, 2, 0, 0, 2, 1, 2, 0, 1, 2, 0, 2, 0, 0, 0, 1, 1, 0, 2, 2, 0, 0,\n",
       "        2, 1, 1, 0, 2, 0, 1, 1, 1, 2, 1, 0, 0, 0, 1, 0, 0, 0, 1, 2, 1, 2,\n",
       "        0, 0, 0, 0, 1, 1, 2, 1, 2, 0, 1, 1, 1, 2, 2, 0, 2, 1, 1, 0, 1, 0,\n",
       "        2, 1, 1, 1, 0, 1, 2, 2, 1, 0, 0, 1, 2, 1, 2, 2, 1, 2, 1, 1, 0, 1,\n",
       "        1, 2, 0, 2, 0, 1, 1, 1, 0, 0, 2, 2, 2, 0, 1, 0, 0, 0, 0, 2, 1, 2,\n",
       "        0, 1, 0, 1, 0, 2, 1, 0, 0, 1, 0, 0, 1, 1, 2, 2, 1, 0, 0, 1, 0, 2,\n",
       "        1, 2, 1, 2, 0, 1, 0, 1, 0, 2, 0, 2, 0, 2, 1, 0, 1, 1, 0, 2, 1, 1,\n",
       "        1, 2, 0, 1, 0, 0, 1, 0, 1, 0, 0, 1, 1, 2, 2, 1, 1, 0, 2, 0, 2, 1,\n",
       "        2, 2, 1, 0, 2, 0, 0, 1, 2, 0, 0, 2, 0, 2, 1, 1, 2, 1, 2, 1, 2, 2,\n",
       "        2, 1, 2, 0, 1, 0, 1, 0, 1, 1, 2, 1, 0, 1, 0, 1, 1, 1, 1, 0, 2, 1,\n",
       "        2, 2, 1, 0, 0, 2, 1, 0, 1, 1, 0, 2, 0, 2, 2, 1, 2, 1, 2, 1, 1, 0,\n",
       "        0, 1, 0, 2, 2, 0, 1, 1, 2, 0, 1, 2, 2, 0, 2, 2, 1, 2, 0, 1, 2, 1,\n",
       "        2, 2, 2, 2, 2, 1, 2, 2, 1, 0, 2, 2, 1, 2, 2, 1, 2, 1, 0, 1, 0, 0,\n",
       "        1, 1, 2, 2, 2, 0, 2, 1, 2, 1, 2, 1, 1, 1, 0, 0, 2, 2, 0, 0, 0, 0,\n",
       "        0, 1, 0, 0, 1, 0, 0, 2, 1, 1, 1, 1, 2, 1, 2, 2, 2, 1, 1, 0, 0, 1,\n",
       "        0, 1, 0, 2, 1, 0, 2, 1, 2, 1, 1, 2, 0, 2, 1, 2, 1, 0, 2, 0, 2, 2,\n",
       "        2, 0, 1, 0, 0, 2, 0, 1, 0, 2, 1, 0, 0, 2, 1, 0, 2, 2, 2, 1, 2, 0,\n",
       "        2, 1, 0, 0, 0, 0, 0, 2, 1, 2, 1, 1, 0, 0, 2, 0, 2, 1, 2, 1, 2, 0,\n",
       "        2, 2, 2, 1, 0, 0, 1, 0, 2, 2, 2, 2, 0, 0, 2, 0, 1, 2, 1, 0, 1, 1,\n",
       "        0, 0, 1, 1, 1, 2, 1, 0, 2, 0, 0, 2, 2, 1, 2, 0, 1, 0, 2, 1, 2, 1,\n",
       "        1, 0, 1, 2, 0, 0, 0, 1, 0, 2, 0, 2, 1, 1, 2, 2, 2, 0, 2, 0, 0, 1,\n",
       "        0, 1, 0, 1, 0, 2, 1, 0, 2, 1, 2, 0, 0, 0, 0, 0, 0, 1, 2, 0, 1, 1,\n",
       "        1, 0, 0, 1, 0, 2, 1, 0, 0, 1, 1, 2, 2, 2, 2, 0, 2, 0, 0, 0, 2, 2,\n",
       "        2, 0, 0, 0, 0, 0, 2, 1, 0, 0, 0, 0, 0, 0, 2, 2, 1, 1, 0, 0, 1, 1,\n",
       "        2, 2, 0, 2, 2, 2, 1, 0, 2, 2, 2, 0, 2, 0, 2, 1, 1, 2, 2, 2, 2, 0,\n",
       "        1, 1, 0, 1, 0, 1, 1, 1, 1, 0, 2, 2, 1, 0, 2, 0, 0, 2, 0, 2, 2, 1,\n",
       "        2, 0, 0, 2, 1, 1, 0, 0, 2, 2, 1, 2, 1, 0, 1, 2, 2, 0, 0, 2, 0, 1,\n",
       "        2, 1, 2, 1, 0, 1, 2, 0, 0, 1, 2, 2, 1, 1, 2, 2, 1, 2, 0, 0, 1, 0,\n",
       "        1, 2, 0, 2, 1, 1, 0, 0, 2, 0, 1, 1, 2, 0, 2, 2, 2, 1, 2, 0, 1, 2,\n",
       "        1, 0, 1, 0, 1, 1, 0, 0, 2, 1, 0, 1, 0, 1, 1, 2, 0, 2, 0, 2, 1, 1,\n",
       "        1, 2, 1, 2, 1, 1, 2, 2, 0, 0, 2, 2, 0, 1, 2, 1, 0, 1, 1, 2, 0, 0,\n",
       "        2, 1, 2, 0, 0, 2, 1, 0, 1, 0, 1, 2, 1, 1, 2, 2, 2, 1, 1, 0, 0, 1,\n",
       "        1, 2, 1, 0, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 1, 0, 1, 2, 0, 0, 0, 2,\n",
       "        1, 2, 1, 0, 1, 2, 0, 0, 1, 2, 1, 2, 0, 1, 2, 0, 2, 2, 1, 1, 2, 0,\n",
       "        2, 1, 0, 0, 0, 2, 1, 2, 2, 0, 2, 1, 0, 1, 1, 2, 0, 0, 0, 0, 0, 2,\n",
       "        0, 2, 2, 2, 2, 0, 1, 2, 2, 1, 0, 0, 1, 1, 2, 0, 1, 2, 0, 2, 1, 0,\n",
       "        0, 2, 1, 1, 0, 1, 1, 1, 0, 1, 2, 2, 0, 1, 2, 2, 2, 1, 2, 1, 2, 2,\n",
       "        1, 1, 0, 2, 0, 2, 2, 0, 2, 2, 2, 0, 2, 2, 1, 1, 2, 1, 1, 0, 0, 0,\n",
       "        0, 2, 2, 1, 1, 1, 2, 0, 1, 1, 1, 1, 1, 2, 0, 2, 2, 0, 1, 2, 2, 0,\n",
       "        1, 0, 0, 2, 0, 2, 0, 2, 0, 1, 1, 1, 2, 2, 0, 1, 1, 2, 2, 2, 1, 0,\n",
       "        1, 2, 1, 0, 0, 0, 2, 0, 0, 2, 1, 2, 2, 1, 0, 0, 2, 0, 1, 1, 1, 1,\n",
       "        1, 0, 0, 1, 1, 0, 0, 1, 0, 2, 0, 0, 2, 0, 1, 1, 2, 1, 2, 0, 2, 0,\n",
       "        2, 1, 0, 2, 1, 0, 1, 2, 1, 2, 0, 2, 1, 0, 0, 1, 2, 0, 0, 0, 1, 1,\n",
       "        0, 0, 1, 1, 1, 2, 0, 1, 1, 2]))"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X,y"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "60ca7cec3e5b73f59d486adfdc739f14bc25da2dd1cabb897d5dc1c8ffe70f93"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
